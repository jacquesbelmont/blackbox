# ============================================================================
# DGX MODE (WEDNESDAY) - Feith REAL DB + vLLM on DGX
# ============================================================================
# Use this on the DGX (or on a jumpbox with network access to Feith + DGX vLLM).
# You only need to replace the values in the sections below.
#
# How to use:
#   cp env.dgx_vllm_feith .env
#   python3 validate_single.py <REAL_FEITH_DOC_ID>
#   python3 wednesday_demo.py

# ----------------------------------------------------------------------------
# FEITH (Source) - REAL
# ----------------------------------------------------------------------------
# Make sure local mock is disabled
FEITH_FORCE_SQLITE=false

# Option A (recommended): set full SQLAlchemy URL for the real DB.
# - If Feith is SQL Server, use mssql+pyodbc URL.
# - If Feith is Oracle, leave FEITH_DB_URL blank and fill FEITH_DB_* below.
FEITH_DB_URL=

# Option B (Oracle placeholder; only used if FEITH_DB_URL is blank)
FEITH_DB_HOST=feith-db.company.com
FEITH_DB_PORT=1521
FEITH_DB_NAME=FEITH_PROD
FEITH_DB_USER=readonly_user
FEITH_DB_PASSWORD=CHANGE_ME

# If Oracle uses schema prefix, set it here
FEITH_DB_SCHEMA=

# IMPORTANT: default read-only
FEITH_WRITEBACK_ENABLED=false

# ----------------------------------------------------------------------------
# TARGET (Destination / Staging)
# ----------------------------------------------------------------------------
# For demo you can use SQLite even on DGX:
TARGET_DB_URL=sqlite:///migration_staging.db
# Or use Postgres if available:
# TARGET_DB_URL=postgresql://migration:pass@localhost:5432/migrated_docs

# ----------------------------------------------------------------------------
# LLM (DGX vLLM)
# ----------------------------------------------------------------------------
# vLLM OpenAI-compatible endpoint
LLM_API_URL=http://localhost:8080/v1/completions
# If your vLLM is chat-based, switch to:
# LLM_API_URL=http://localhost:8080/v1/chat/completions

# Model name must match /v1/models output
LLM_MODEL=llama-3.1-70b

# ----------------------------------------------------------------------------
# Processing
# ----------------------------------------------------------------------------
BATCH_SIZE=100
CONFIDENCE_THRESHOLD=0.7
MAX_WORKERS=4

# ----------------------------------------------------------------------------
# Runtime
# ----------------------------------------------------------------------------
LOG_LEVEL=INFO
MAX_RETRIES=3
LLM_TIMEOUT=180
